1. Goal
   Develop a data-driven ML model to predict IE (inhibition efficiency) from molecular and operating-condition features, enabling optimization of inhibitor structure and dosage.

2. Problem Definition
   - Input features: C# (carbon number), Mw (molecular weight), HLB (hydrophilic-lipophilic balance), EO (ethylene oxide units), Conc (concentration), pH
   - Target: IE (inhibition efficiency)
   - AA (active agent) is used to rescale IE during preprocessing

3. Data Collection & Understanding
   - ~300 lab samples from corrosion experiments
   - Each sample includes inhibitor formulation (C#, Mw, HLB, EO), test conditions (Conc, pH), and measured IE

4. Data Preprocessing (preprocessing.py)
   - Load raw dataset, remove non-informative columns
   - Compute IE = IE × AA / 100, then drop AA
   - Drop duplicates and rows with missing IE
   - Split into train/val/test (70/15/15)
   - Fit imputer (mean) and scaler (StandardScaler) on TRAIN only, transform all splits
   - Outputs in data/processed/: train.csv, val.csv, test.csv, cleaned_full.csv
   - Archive: data/archive/dataset_original.csv

5. Exploratory Data Analysis (eda.py)
   - Histograms for all features and IE
   - Pearson correlation heatmap
   - Scatter plots of IE vs key drivers (Conc, pH, HLB, EO)
   - Outputs in data/eda/: histograms.png, correlation_heatmap.png, scatter_plots.png

6. Feature Engineering & Selection (features.py, feature_importance.py)
   - Canonical feature set: C#, Mw, HLB, EO, Conc, pH → IE
   - features.py: loads preprocessed splits, exposes X/y for train/val/test
   - feature_importance.py: baseline importance via linear regression coefficients, RF importances, permutation importance
   - Output: data/feature_importance/baseline_importance.csv

7. Model Selection & Training (train.py)
   - Load preprocessed splits (already imputed + scaled)
   - Tune models on TRAIN using RandomizedSearchCV (3-fold CV, 18 iterations)
   - Evaluate on VAL, pick winner by R²
   - Refit winner on TRAIN+VAL
   - Evaluate on TEST
   - Candidates: RandomForestRegressor, SVR (RBF)
   - Best: RandomForestRegressor (n_estimators=600, max_depth=6, min_samples_leaf=2)
     - Val: R²=0.693, RMSE=20.4
     - Test: R²=0.417, RMSE=20.1
   - Outputs in data/models/: results.json, test_predictions.csv

8. Model Evaluation & Interpretation
   (TODO)

9. Optimization & Design Use-Case
   (TODO)
